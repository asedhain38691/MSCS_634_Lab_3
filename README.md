# MSCS_634_Lab_3


The purpose of this lab was to implement and compare two clustering algorithms: K-Means and K-Medoids, on the Wine dataset to evaluate their effectiveness in identifying natural groupings within the data. After standardizing the features and training both models with k = 3, I found that K-Means achieved a higher Silhouette Score (0.2849) and Adjusted Rand Index (0.8975) compared to K-Medoids (0.2676 and 0.7411, respectively). This indicates that K-Means produced more cohesive and better-aligned clusters relative to the true class labels. While K-Medoids can be more robust to outliers, in this dataset K-Means performed more efficiently due to the relatively clean and well-separated features. One challenge I encountered was getting the K-Medoids implementation to run correctly in Google Colab, which required installing the scikit-learn-extra library and restarting the runtime. Overall, this lab reinforced my understanding of how clustering algorithms differ in sensitivity, performance, and suitability depending on dataset characteristics.
